{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQ1gobUdJmUNnsoERPF2uy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/360abhi/React-animations/blob/main/Zeus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "collapsed": true,
        "id": "8-20WP2UP2WO"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "import re\n",
        "\n",
        "# spacy.cli.download(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "pre_def_verbs = ['click','submit','review','edit','enter','view','check','access','select','authorize']\n",
        "\n",
        "\n",
        "def remove_articles(sentence):\n",
        "    pattern = r'\\b(?:a|an|the)\\b'\n",
        "    cleaned_sentence = re.sub(pattern, '', sentence, flags=re.IGNORECASE)\n",
        "    cleaned_sentence = re.sub(r'\\s+', ' ', cleaned_sentence).strip()\n",
        "    return cleaned_sentence\n",
        "\n",
        "\n",
        "def find_screen_names(sentence):\n",
        "    sentence = remove_articles(sentence)\n",
        "    # pattern = r\"(?i)(?:move to|navigate to|switch to)\\s+'?(?:the|a)?\\s*([\\w\\s]+)'?(?:\\s+tab|\\s+screen|\\s+page|\\s+window)?|'([\\w\\s]+)'\\s+(?:tab|screen|page|window)|(?:\\bin\\b)\\s+'?([\\w]+)\\s+(?:tab|screen|page|window)'?\"\n",
        "    pattern = r'(?i)(?:move to|navigate to|switch to)\\s+(\\w+)|(\\w+)\\s+(?:tab|screen|page|window)'\n",
        "    matches = re.findall(pattern, sentence)\n",
        "    screen_names = [name1 or name2 for name1, name2 in matches if name1 or name2]\n",
        "\n",
        "    # Remove duplicates\n",
        "    screen_names = list(set(screen_names))\n",
        "    return screen_names\n",
        "\n",
        "def separate_screen_words(screen_names):\n",
        "    words = []\n",
        "    for name in screen_names:\n",
        "        words.extend(name.split())\n",
        "        words.extend(['tab','screen','window'])\n",
        "    return words\n",
        "\n",
        "\n",
        "def extract_action_verbs(sentence):\n",
        "\n",
        "\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "    action_verbs = []\n",
        "\n",
        "    field =[]\n",
        "    dfield=[]\n",
        "\n",
        "    screens = []\n",
        "    sep_screens=[]\n",
        "\n",
        "    data =[]\n",
        "\n",
        "    screens = find_screen_names(sentence)\n",
        "    sep_screens = separate_screen_words(screens)\n",
        "    # print(sep_screens)\n",
        "\n",
        "\n",
        "    rootToken = next(token for token in doc if token.dep_ == \"ROOT\")\n",
        "\n",
        "\n",
        "    for index,token in enumerate(doc):\n",
        "\n",
        "            if token.dep_ == \"ROOT\":\n",
        "\n",
        "                # Check if ROOT and does not have xcomp children\n",
        "\n",
        "                if not any(child.dep_ in [\"ccomp\",\"xcomp\",\"pcomp\"] for child in token.children):\n",
        "\n",
        "                  if token.pos_ == \"VERB\":\n",
        "\n",
        "                    action_verbs.append(token.text)\n",
        "\n",
        "                    if token.text.lower() not in pre_def_verbs:\n",
        "\n",
        "                      pre_def_verbs.append(token.text.lower())\n",
        "\n",
        "                      # print(token.text.lower())\n",
        "\n",
        "                  elif token.pos_ == \"PROPN\" and token.text not in screens:\n",
        "                    field.append(token.text)\n",
        "\n",
        "\n",
        "\n",
        "                # If ROOT and has xcomp children, skip ROOT but consider xcomp\n",
        "\n",
        "                else:\n",
        "\n",
        "                    for child in token.children:\n",
        "\n",
        "                        if child.dep_ in [\"ccomp\",\"pcomp\",\"xcomp\"] and child.pos_ == \"VERB\":\n",
        "\n",
        "\n",
        "\n",
        "                            action_verbs.append(child.text)\n",
        "\n",
        "                            if child.text.lower() not in pre_def_verbs:\n",
        "\n",
        "                              pre_def_verbs.append(child.text.lower())\n",
        "\n",
        "                              # print(child.text.lower())\n",
        "\n",
        "\n",
        "            elif token.dep_ in [\"xcomp\",\"ccomp\",\"pcomp\"]:\n",
        "\n",
        "              # print(\"Insidexcomp\", token.text)\n",
        "\n",
        "              try:\n",
        "\n",
        "                if token.head.text != rootToken.text:\n",
        "\n",
        "                  if token.pos_ == \"VERB\":\n",
        "\n",
        "                    action_verbs.append(token.text)\n",
        "\n",
        "                    if token.text.lower() not in pre_def_verbs:\n",
        "\n",
        "                      pre_def_verbs.append(token.text.lower())\n",
        "\n",
        "                      # print(token.text.lower())\n",
        "\n",
        "\n",
        "\n",
        "                    # for child in token.children:\n",
        "\n",
        "\n",
        "\n",
        "                    #   if child.dep_ == \"dobj\":\n",
        "\n",
        "                    #       field = child.text\n",
        "\n",
        "\n",
        "\n",
        "              except:\n",
        "\n",
        "                pass\n",
        "\n",
        "            elif token.dep_ == \"conj\":\n",
        "\n",
        "                # Check if conj has xcomp children and the child is a verb\n",
        "\n",
        "                if any(child.dep_ in [\"xcomp\",\"pcomp\",\"ccomp\"] and child.pos_ == \"VERB\" for child in token.children):\n",
        "\n",
        "                    for child in token.children:\n",
        "\n",
        "                        if child.dep_ in [\"xcomp\",\"pcomp\",\"ccomp\"] and child.pos_ == \"VERB\":\n",
        "\n",
        "                            action_verbs.append(child.text)\n",
        "\n",
        "                            if child.text.lower() not in pre_def_verbs:\n",
        "\n",
        "                              pre_def_verbs.append(child.text.lower())\n",
        "\n",
        "                              # print(child.text.lower())\n",
        "\n",
        "\n",
        "\n",
        "                            # for child in token.children:\n",
        "\n",
        "\n",
        "\n",
        "                            #   if child.dep_ == \"dobj\":\n",
        "\n",
        "                            #       field = child.text\n",
        "\n",
        "\n",
        "\n",
        "                # If conj itself is a verb and has no xcomp children, append conj\n",
        "\n",
        "                elif token.pos_ == \"VERB\":\n",
        "\n",
        "                    action_verbs.append(token.text)\n",
        "\n",
        "                    if token.text.lower() not in pre_def_verbs:\n",
        "\n",
        "                      pre_def_verbs.append(token.text.lower())\n",
        "\n",
        "\n",
        "                    # for child in token.children:\n",
        "\n",
        "\n",
        "\n",
        "                    #   if child.dep_ == \"dobj\":\n",
        "\n",
        "                    #       field = child.text\n",
        "\n",
        "\n",
        "\n",
        "            if token.dep_ in [\"dobj\",\"pobj\",\"PROPN\"] and token.text not in sep_screens:\n",
        "\n",
        "              # field.append(token.text)\n",
        "\n",
        "              var_field = token.text\n",
        "\n",
        "              dfield.append(token.text)\n",
        "\n",
        "              prev = doc[index-1]\n",
        "\n",
        "\n",
        "              if prev.pos_ in [\"NOUN\",\"ADJ\",\"PROPN\"] and prev.text not in sep_screens:\n",
        "\n",
        "                # field.append(prev.text)\n",
        "\n",
        "                var_field = prev.text + \" \" + var_field\n",
        "\n",
        "                dfield.append(prev.text)\n",
        "\n",
        "                # print(var_field)\n",
        "\n",
        "                prev2 = doc[index-2]\n",
        "\n",
        "                if prev2.pos_ in [\"NOUN\",\"ADJ\",\"PROPN\"] and prev2.text not in sep_screens:\n",
        "\n",
        "                  var_field = prev2.text + \" \" + var_field\n",
        "\n",
        "                  # field.append(var_field)\n",
        "                  dfield.append(prev2.text)\n",
        "\n",
        "                  # print(var_field)\n",
        "\n",
        "              field.append(var_field)\n",
        "\n",
        "            # if token.dep_ in [\"pobj\"] and token.text not in sep_screens and len(field) == 0:\n",
        "\n",
        "            #   # field.append(token.text)\n",
        "\n",
        "            #   # var_field = token.text\n",
        "\n",
        "            #   field.append(token.text)\n",
        "\n",
        "            #   prev = doc[index-1]\n",
        "\n",
        "\n",
        "            #   if prev.pos_ in [\"NOUN\",\"ADJ\",\"PROPN\"] and prev.text not in sep_screens:\n",
        "\n",
        "            #     # field.append(prev.text)\n",
        "\n",
        "            #     # var_field = prev.text + \" \" + var_field\n",
        "\n",
        "            #     field.append(prev.text)\n",
        "\n",
        "            #     # print(var_field)\n",
        "\n",
        "            #     prev2 = doc[index-2]\n",
        "\n",
        "            #     if prev2.pos_ in [\"NOUN\",\"ADJ\",\"PROPN\"] and prev2.text not in sep_screens:\n",
        "\n",
        "            #       # var_field = prev2.text + \" \" + var_field\n",
        "\n",
        "            #       field.append(prev2.text)\n",
        "\n",
        "\n",
        "            # if token.dep_ in [\"pobj\"] and token.text not in sep_screens and len(field) !=0:\n",
        "\n",
        "            #   # field.append(token.text)\n",
        "\n",
        "            #   # var_field = token.text\n",
        "\n",
        "            #   data.append(token.text)\n",
        "\n",
        "            #   prev = doc[index-1]\n",
        "\n",
        "\n",
        "            #   if prev.pos_ in [\"NOUN\",\"ADJ\",\"PROPN\"] and prev.text not in sep_screens:\n",
        "\n",
        "            #     # field.append(prev.text)\n",
        "\n",
        "            #     # var_field = prev.text + \" \" + var_field\n",
        "\n",
        "            #     data.append(prev.text)\n",
        "\n",
        "            #     # print(var_field)\n",
        "\n",
        "            #     prev2 = doc[index-2]\n",
        "\n",
        "            #     if prev2.pos_ in [\"NOUN\",\"ADJ\",\"PROPN\"] and prev2.text not in sep_screens:\n",
        "\n",
        "            #       # var_field = prev2.text + \" \" + var_field\n",
        "\n",
        "            #       data.append(prev2.text)\n",
        "\n",
        "\n",
        "    # PRD check\n",
        "\n",
        "    for token in doc:\n",
        "\n",
        "      if token.text.lower() not in action_verbs and token.text.lower() in pre_def_verbs and token.text not in field and token.text not in dfield:\n",
        "        action_verbs.append(token.text)\n",
        "\n",
        "    action_verbs = list(set(action_verbs))\n",
        "    field = list(set(field))\n",
        "    screens = list(set(screens))\n",
        "    # data = list(set(data))\n",
        "\n",
        "\n",
        "\n",
        "    return action_verbs,field,screens\n",
        "\n",
        "\n",
        "\n",
        "sentences = [\n",
        "\n",
        "\n",
        "\n",
        "    # \"The operational maker should be able to log in to ARX as Operational Maker and see all products as per entitlement.\",\n",
        "\n",
        "\n",
        "\n",
        "    \"In package tab Click on Create Package button\",\n",
        "\n",
        "\n",
        "\n",
        "    # \"The user should be able to click on the create package button.\",\n",
        "\n",
        "\n",
        "\n",
        "    \"The system should allow the user to enter all details, and after clicking the next button, it should navigate to the 'Products' tab.\",\n",
        "\n",
        "\n",
        "\n",
        "    # \"The bank user should be able to select all the products.\",\n",
        "\n",
        "\n",
        "\n",
        "    # \"The bank user should be able to select all the charge fields.\",\n",
        "\n",
        "\n",
        "\n",
        "    # \"The bank user should be able to select all the billing details.\",\n",
        "\n",
        "\n",
        "\n",
        "    # \"The bank user should be able to select the template and report for collections + J54.\",\n",
        "\n",
        "\n",
        "\n",
        "    # \"The bank user should be able to select the template and report for payments.\",\n",
        "\n",
        "\n",
        "\n",
        "    # \"The bank user should be able to select the template for the common report.\",\n",
        "\n",
        "\n",
        "\n",
        "    # \"The checker should be able to log in to CIM.\",\n",
        "\n",
        "\n",
        "\n",
        "    # \"After clicking save, he submitted the Form\",\n",
        "\n",
        "\n",
        "\n",
        "    # \"User should select the charges as done\",\n",
        "\n",
        "    # \"Access and Login into ARX Page\",\n",
        "\n",
        "    # \"Review and Submit Package\"\n",
        "\n",
        "\n",
        "\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "afeQGOOXY_0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "import re\n",
        "\n",
        "\n",
        "def print_colored_sentence(sentence, words, fields,screens):\n",
        "\n",
        "    words_set = set(words)\n",
        "\n",
        "    fields_set = set(fields)\n",
        "\n",
        "    screen_set = set(screens)\n",
        "\n",
        "    # data_set = set(data)\n",
        "\n",
        "    color =\"red\"\n",
        "\n",
        "    color_field = \"blue\"\n",
        "\n",
        "    colored_sentence = \"\"\n",
        "\n",
        "\n",
        "\n",
        "    for word in sentence.split():\n",
        "\n",
        "        word = re.sub(r'[^\\w\\s]', '', word)\n",
        "\n",
        "        if word in words_set:\n",
        "\n",
        "             colored_sentence += (\n",
        "\n",
        "                f'<span style=\"color: {\"black\"}; background-color: {\"yellow\"}; font-weight: bold;\">{word}</span> '\n",
        "\n",
        "            )\n",
        "\n",
        "        elif word in fields_set:\n",
        "\n",
        "          colored_sentence += (\n",
        "\n",
        "                f'<span style=\"color: {\"white\"}; background-color: {\"blue\"}; font-weight: bold;\">{word}</span> '\n",
        "\n",
        "            )\n",
        "\n",
        "        # elif word in data_set:\n",
        "\n",
        "        #   colored_sentence += (\n",
        "\n",
        "        #         f'<span style=\"color: {\"white\"}; background-color: {\"blue\"}; font-weight: bold;\">{word}</span> '\n",
        "\n",
        "        #     )\n",
        "\n",
        "        else:\n",
        "\n",
        "            colored_sentence += word + \" \"\n",
        "\n",
        "    for screen in screens:\n",
        "\n",
        "      if screen in sentence:\n",
        "\n",
        "        colored_sentence = colored_sentence.replace(screen, f'<span style=\"color: {\"white\"}; background-color: {\"green\"}; font-weight: bold;\">{screen}</span>')\n",
        "\n",
        "\n",
        "\n",
        "    # for field in fields:\n",
        "\n",
        "    #   if field in sentence:\n",
        "\n",
        "    #     colored_sentence = colored_sentence.replace(field, f'<span style=\"color: {\"white\"}; background-color: {\"blue\"}; font-weight: bold;\">{field}</span>')\n",
        "\n",
        "\n",
        "\n",
        "    display(HTML(colored_sentence.strip()))\n",
        "\n",
        "import string\n",
        "\n",
        "def remove_punctuation(sentence):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return sentence.translate(translator)\n",
        "\n",
        "\n",
        "\n",
        "for sentence in sentences:\n",
        "    sentence = remove_punctuation(sentence)\n",
        "\n",
        "    action_verbs,fields,screens = extract_action_verbs(sentence)\n",
        "    print(action_verbs)\n",
        "    print(fields)\n",
        "\n",
        "    print_colored_sentence(sentence, action_verbs,fields,screens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "pgfA9YOu3AAN",
        "outputId": "ad694092-eccf-4ecd-c435-1a56f9f7bfd6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Click']\n",
            "['Create Package button']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "In <span style=\"color: white; background-color: green; font-weight: bold;\">package</span> tab <span style=\"color: black; background-color: yellow; font-weight: bold;\">Click</span> on Create Package button"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['navigate', 'enter', 'clicking']\n",
            "['next button', 'details']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The system should allow the user to <span style=\"color: black; background-color: yellow; font-weight: bold;\">enter</span> all <span style=\"color: white; background-color: blue; font-weight: bold;\">details</span> and after <span style=\"color: black; background-color: yellow; font-weight: bold;\">clicking</span> the next button it should <span style=\"color: black; background-color: yellow; font-weight: bold;\">navigate</span> to the <span style=\"color: white; background-color: green; font-weight: bold;\">Products</span> tab"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FglG52buZAtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "file_path = 'CIM_TestCases.xlsx'\n",
        "df = pd.read_excel(file_path,\"Onboarding Package\")\n",
        "\n",
        "step_summary_column = df['Step Summary']\n",
        "\n",
        "def split_sentences(text):\n",
        "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
        "    return sentences\n",
        "\n",
        "def contains_number(sentence):\n",
        "    return bool(re.search(r'\\d', sentence))\n",
        "\n",
        "def is_text_sentence(sentence):\n",
        "    return not contains_number(sentence) and sentence.strip()\n",
        "\n",
        "all_sentences = []\n",
        "\n",
        "for index,text in enumerate(step_summary_column):\n",
        "    if pd.notna(text):\n",
        "        sentences = split_sentences(text)\n",
        "        filtered_sentences = [s for s in sentences if is_text_sentence(s)]\n",
        "        all_sentences.append(filtered_sentences)\n",
        "\n",
        "for idx, sentences in enumerate(all_sentences[1:2]):\n",
        "    print(f\"TestCase {idx + 1}:\")\n",
        "    for sentence in sentences:\n",
        "      action_verbs,fields,screen = extract_action_verbs(sentence)\n",
        "      print_colored_sentence(sentence, action_verbs,fields,screen)\n",
        "      print()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "FJcyzpDb3TA4",
        "outputId": "e6503fb1-9ba3-4284-a167-190ecba0e863",
        "collapsed": true
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TestCase 1:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span style=\"color: black; background-color: yellow; font-weight: bold;\">Login</span> into <span style=\"color: white; background-color: blue; font-weight: bold;\">ARX</span> with Operational maker credential"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span style=\"color: black; background-color: yellow; font-weight: bold;\">Click</span> On <span style=\"color: white; background-color: blue; font-weight: bold;\">CIM</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "In <span style=\"color: white; background-color: green; font-weight: bold;\">package</span> tab <span style=\"color: black; background-color: yellow; font-weight: bold;\">Click</span> on Create Package <span style=\"color: white; background-color: blue; font-weight: bold;\">button</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "In <span style=\"color: white; background-color: blue; font-weight: bold;\">details</span> <span style=\"color: black; background-color: yellow; font-weight: bold;\">enter</span> all mandatory <span style=\"color: white; background-color: blue; font-weight: bold;\">details</span> and <span style=\"color: black; background-color: yellow; font-weight: bold;\">select</span> customization as not allowed and digital channel as not allowed and <span style=\"color: black; background-color: yellow; font-weight: bold;\">click</span> on next button"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span style=\"color: black; background-color: yellow; font-weight: bold;\">Login</span> into <span style=\"color: white; background-color: blue; font-weight: bold;\">ARX</span> with checker ID"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span style=\"color: black; background-color: yellow; font-weight: bold;\">Click</span> on <span style=\"color: white; background-color: blue; font-weight: bold;\">CIM</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span style=\"color: black; background-color: yellow; font-weight: bold;\">Authorize</span> the <span style=\"color: white; background-color: blue; font-weight: bold;\">package</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def convert_to_sentences(text):\n",
        "    lines = text.split('\\n')\n",
        "    sentences = []\n",
        "\n",
        "    for line in lines:\n",
        "        cleaned_sentence = re.sub(r'^\\d+\\.\\s*', '', line)\n",
        "        if cleaned_sentence.strip():\n",
        "            sentences.append(cleaned_sentence.strip())\n",
        "\n",
        "    return sentences\n",
        "\n",
        "file_path = 'CIM_TestCases.xlsx'\n",
        "df = pd.read_excel(file_path,\"Onboarding Package\")\n",
        "\n",
        "step_summary_column = df['Step Summary']\n",
        "\n"
      ],
      "metadata": {
        "id": "Fy1zlryKaPk8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def create_test_case_json(test_case_num, steps):\n",
        "    test_case_json = {test_case_num: []}\n",
        "    for index,step in enumerate(steps):\n",
        "        action_verbs,fields,screen = extract_action_verbs(step)\n",
        "        test_case_json[test_case_num].append({\n",
        "            'seq': index+1,\n",
        "            'field': fields if isinstance(fields, list) else [fields],\n",
        "            'action': action_verbs if isinstance(action_verbs, list) else [action_verbs],\n",
        "            'screen': screen if isinstance(screen, list) else [screen]\n",
        "        })\n",
        "    return test_case_json\n",
        "\n",
        "all_test_cases = {}\n",
        "\n",
        "for index,step in enumerate(step_summary_column[1:300]):\n",
        "  step = convert_to_sentences(step)\n",
        "  myfil = create_test_case_json(index+1,step)\n",
        "  all_test_cases.update(myfil)\n",
        "  # print(myfil)\n",
        "\n",
        "\n",
        "with open('testcase.json', 'w') as file:\n",
        "    json.dump(all_test_cases, file, indent=4)\n",
        "\n",
        "print(\"Test cases have been written to testcase.json\")\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI4CwPKNZBim",
        "outputId": "9803da7d-3c77-4fbe-e819-cb4c75ac03e1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test cases have been written to testcase.json\n"
          ]
        }
      ]
    }
  ]
}